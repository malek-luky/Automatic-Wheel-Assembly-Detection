{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Car Wheel Assembly Detection \ud83d\ude98","text":"<p>Authors: Elizaveta Isianova, Lukas Malek, Lukas Rasocha, Vratislav Besta, Weihang Li</p>"},{"location":"#tech-stack-tools","title":"\u2699\ufe0f Tech Stack &amp; Tools","text":""},{"location":"#project","title":"\ud83d\udcdd Project","text":"<p>This project presents an attempt to find a solution for predicting the successful assembly of tires onto wheels autonomously. Currently, the method uses purely an image based classification to predict whether the tire was assembled correctly. To enrich this, we attempt to use an LSTM model to analyze inputs from torque and force sensors of the assembling robot, enabling the system to determine the optimal conditions for tire assembly without human intervention. The goal is to increase efficiency and accuracy in tire assembly processes, reducing the reliance on manual labor and minimizing errors.</p>"},{"location":"#motivation","title":"Motivation","text":"<p>The project is based on real case situated within the Testbed for Industry 4.0 at CTU Prague. The current quality control methodology uses CNNs for the visual inspection of tire assemblies.</p>"},{"location":"#data","title":"Data","text":"<p>Data are meassured and labelled by the lab. The dataset is generated through robotic cell runs, every sample is then labeled as true (successful assembly) or false (unsuccessful assembly).</p>"},{"location":"#project-goal","title":"Project Goal","text":"<p>This project aims to introduce a new method for enhancing the quality control process in car wheel assembly executed by a delta robot.</p>"},{"location":"#approach","title":"Approach","text":"<p>Departing from the picture-based assessment using CNNs, our approach aims to evaluate the correctness of the assembly based on the data from a force-torque sensor. This transforms the dataset into a collection of time series, capturing recorded sensor data from individual tire assemblies. Each element from the series is a 6D vector combining a 3 DOF force vector and a 3 DOF torque vector.</p>"},{"location":"#methodology","title":"Methodology","text":"<p>The chosen methodology is an implementation of Long Short-Term Memory Recurrent Neural Networks (LSTM RNNs) using PyTorch since the data are in timeseries. There is no existing baseline solution for the current problem. Therefore the project could be evaluated and compared to the existing CNN approach.</p>"},{"location":"#limitations","title":"Limitations","text":"<p>Due to the small dataset limited by the time constraints and the amount of labelled data, we don't expect to obtain a well performing model, but rather want to present a method for further development.</p>"},{"location":"#framework","title":"Framework","text":"<p>As a third-party framework we are going to use PyTorch Lightning and maybe with a Pytorch Forecasting package built on top of the Lightning.</p>"},{"location":"#conda-installation","title":"\ud83d\udc0d Conda Installation","text":""},{"location":"#create-the-environment-install-the-dependencies-and-download-the-data","title":"Create the environment, install the dependencies and download the data","text":"<pre><code>git clone https://github.com/malek-luky/Automatic-Wheel-Assembly-Detection.git\ncd Automatic-Wheel-Assembly-Detection\nmake conda\n</code></pre>"},{"location":"#docker","title":"\ud83d\udc33 Docker","text":"<p>This will build an image of our project and run it in a container. In the container you will have all the dependencies, data and code needed to run the project. We have three different dockerfiles: - conda_setup: debugging purposes, sets the environement and waits for user to run it in interactive mode - train_model: downloads dependencies, trains model and send it to Weight and Biases (wandb) - deploy_model: downloads dependencies and the model from wandb and waits for user input to make predictions</p> <p>The following steps to build and run are written for train_model only, but it can be easily changed for any dockerfile.</p>"},{"location":"#build-the-container-locally-after-downloading-the-repository","title":"Build the container locally after downloading the repository.","text":"<pre><code>git clone https://github.com/malek-luky/Automatic-Wheel-Assembly-Detection.git\ncd Automatic-Wheel-Assembly-Detection\ndocker build -f dockerfiles/train_model.dockerfile . -t trainer:latest\ndocker run --name trainer -e WANDB_API_KEY=&lt;WANDB_API_KEY&gt; trainer:latest\n</code></pre>"},{"location":"#pulls-the-docker-image-from-gcp-artifact-registry","title":"Pulls the docker image from GCP Artifact Registry","text":"<pre><code>make docker_train_online\ndocker run --name trainer -e WANDB_API_KEY=&lt;WANDB_API_KEY&gt; trainer:latest\n</code></pre>"},{"location":"#google-cloud-computing","title":"\ud83d\udcbb Google Cloud Computing","text":""},{"location":"#create-vm-machine-in-gcp","title":"Create VM Machine in GCP","text":"<ol> <li>Open Compute Engine</li> <li>Create a name</li> <li>Region: <code>europe-west1 (Belgium)</code></li> <li>Zone: <code>europe-west1-b</code></li> <li>Machine configuration: <code>Compute-optimized</code></li> <li>Series: <code>C2D</code></li> <li>Machine Type: <code>c2d-standard-4</code> (must have at least 16GB RAM)</li> <li>Boot disk: <code>20 GB</code></li> <li>Container image: <code>&lt;ADDRESS-OF-IMAGE-IN-ARTIFACT-REGISTRY&gt;</code> (click Deploy Container)</li> <li>Restart policy: <code>never</code></li> <li>The rest is default</li> </ol>"},{"location":"#via-gcloud-command","title":"Via gcloud command","text":"<p>If the <code>gcloud</code> command is unkown, follow the steps for your OS. Otherwise there are three three dockerfiles that can be deployed to Virtual Machine in GCP. All of the create the same instance but with specific container. The instance of the name is folowing the dockerfile name (conda_setup/train_model/deploy_model)</p> <pre><code>make conda_setup_vm\nmake train_model_vm\nmake deploy_model_vm\n</code></pre>"},{"location":"#connecting-to-vm-machine","title":"Connecting to VM machine","text":"<ul> <li>Can be via SSH inside the browser Compute Engine</li> <li>Or locally using command similar to this one <code>gcloud compute ssh --zone \"europe-west1-b\" \"&lt;name_of_instance&gt;\" --project \"wheel-assembly-detection\"</code> (the instatnces can be listed using <code>gcloud compute instances list</code>)</li> </ul>"},{"location":"#controlling-deployed-virtual-machine","title":"Controlling deployed Virtual Machine","text":"<ul> <li><code>docker ps</code>: shows the docker files running on the machine</li> <li><code>docker logs &lt;CONATINER_ID&gt;</code> wait until its successfully pulled</li> <li><code>docker ps</code>: pulled container has new ID</li> <li><code>docker exec -it CONTAINER-ID /bin/bash</code>: starts the docker in interactive window (only the conda_wheel_assemly_detection, the rest only train the model, upload the model and exits, maybe setting the restart policy to \"never\" should fix this issue)</li> </ul>"},{"location":"#optional","title":"\ud83d\udc40 Optional","text":"<p>It re-creates <code>filtered</code>, <code>normalized</code> and <code>processed</code> folders. The processed data is stored in <code>data/processed/dataset_concatenated.csv</code> and is used for training.</p>"},{"location":"#re-process-the-data","title":"Re-process the data","text":"<pre><code>python src/data/make_dataset.py\n</code></pre>"},{"location":"#re-train-the-model","title":"Re-train the model","text":"<pre><code>python src/models/train_model.py\n</code></pre>"},{"location":"#run-training-locally-without-wb","title":"Run training locally without W&amp;B","text":"<pre><code>python src/models/train_model.py\n</code></pre>"},{"location":"#run-training-locally-with-wb","title":"Run training locally with W&amp;B","text":"<pre><code>python src/models/train_model.py --wandb_on\n</code></pre>"},{"location":"#remove-the-conda-environment","title":"Remove the conda environment","text":"<pre><code>conda remove --name DTU_ML_Ops --all\n</code></pre>"},{"location":"#deployment","title":"\ud83c\udf10 Deployment","text":"<p>This repository is configured for deployment using Google Cloud\ufe0f \u2601\ufe0f. The images in this repository are re-built and deployed automatically using GitHub Actions and stored in Google Artifact Registry on every push to the <code>main</code> branch.</p> <p>We also automatically re-train the model using Vertex AI, store it in Weights &amp; Biases model registry and deploy it using Google Cloud Run.</p>"},{"location":"#automatic-workflows","title":"Automatic Workflows","text":"<p>With access to GCP you can simply make your changes and merge it into main. When the merge is done, GitHub Actions will automatically train and deploy the model. We have 4 workflows in total. - build_conda: build the image and stores in in GCP - build_train: runs the built image on Vertex AI to train the model and sends it to wandb  - build_deploy: deploy the image to cloud run to handle user requests and via FastAPI gives predictions</p>"},{"location":"#use-our-model","title":"\ud83e\udd16 Use our model","text":""},{"location":"#cloud-deployment","title":"Cloud Deployment","text":"<p>The model is deployed using Google Cloud Run. You can make a prediction using the following command:</p> <pre><code>curl -X 'POST' \\\n  'https://deployed-model-service-t2tcujqlqq-ew.a.run.app/predict' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"sequence\": [\n        [0.1, 0.2, 0.3, 0.2, 0.3, 0.4, 0.2, 0.1],\n        [0.2, 0.3, 0.4, 0.3, 0.4, 0.5, 0.3, 0.2],\n        [0.1, 0.2, 0.3, 0.2, 0.3, 0.4, 0.2, 0.1],\n        [0.1, 0.2, 0.3, 0.2, 0.3, 0.4, 0.2, 0.1],\n        [0.1, 0.2, 0.3, 0.2, 0.3, 0.4, 0.2, 0.1],\n        [0.1, 0.2, 0.3, 0.2, 0.3, 0.4, 0.2, 0.1],\n        [0.1, 0.2, 0.3, 0.2, 0.3, 0.4, 0.2, 0.1],\n        [0.1, 0.2, 0.3, 0.2, 0.3, 0.4, 0.2, 0.1],\n        [0.1, 0.2, 0.3, 0.2, 0.3, 0.4, 0.2, 0.1],\n        [0.2, 0.3, 0.4, 0.3, 0.4, 0.5, 0.3, 0.2]\n    ]\n}'\n</code></pre>"},{"location":"#local-deployment","title":"Local deployment","text":"<p>Our model can also be deployed locally. The guidelines for running a local server and making predictions are here</p>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>Contributions are always welcome! If you have any ideas or suggestions for the project, please create an issue or submit a pull request. Please follow these conventions for commit messages.</p>"},{"location":"#technology-used","title":"\ud83d\udcbb Technology Used","text":"<ul> <li>Docker: \"PC Setup\" inside the docker file</li> <li>Conda: Package manager</li> <li>GCP<ul> <li>Cloud Storage: Stores data for dvc pull</li> <li>Artifact Registry: Stores built docker images (can be created into container)</li> <li>Compute Engine: Enables creating virtual machines</li> <li>Functions / Run: Deployment</li> <li>Vertex AI: includes virtual machines, training of AI models (\"abstraction above VM...\")</li> </ul> </li> <li>OmegaConf: Handle the config data for train_model.py</li> <li>CodeCov: Creates the coverage report and submit it as a comments to the pull request </li> <li>CookieCutter: Template used for generating code sctructure</li> <li>DVC: Data versioning tool, similar is github but for data</li> <li>GitHub: Versioning tool for written code</li> <li>GitHub Actions: Run pytest, Codecov and upload built docker images to GCP</li> <li>Pytest: Runs some tests to check whether the code is working</li> <li>CodeCov: Tool for uploading coverage report from pytest as a comment to pull requests</li> <li>Weight and Biases: wandb, used for storing and tracking the trained model</li> <li>Pytorch Lightning: Framework for training our LTSM model and storing default config values</li> <li>Forecasting: Abstracion above Pytorch Lightning working with Timeseries data</li> <li>Torchserve: Used for local deployment</li> <li>FastAPI: Creates API for our model, wrap it into container so it can be accessed anywhere</li> <li>Slack/SMS: Handle the alerts, Slack for deployed model, SMS for a server cold-run</li> </ul>"},{"location":"#diagram","title":"DIAGRAM","text":""},{"location":"#project-structure","title":"\ud83d\udcc2 PROJECT STRUCTURE","text":"<p>The directory structure of the project looks like this:</p> <pre><code>\u251c\u2500\u2500 .dvc/                 &lt;- Cache and config for data version control\n\u251c\u2500\u2500 .github/workflows     &lt;- Includes the steps for GitHub Actions\n\u2502   \u2514\u2500\u2500 build_conda       &lt;- Conda dockerfile: Build conda image and push it to GCP\n\u2502   \u251c\u2500\u2500 build_deploy      &lt;- Deploy dockerfile: build, push and deploy\n\u2502   \u2514\u2500\u2500 build_train       &lt;- Train dockerfile: Build train image and push it to GCP\n\u2502   \u2514\u2500\u2500 pytests           &lt;- Runs the data and model pytests\n\u251c\u2500\u2500 data                  &lt;- Run dvc pull to see this folder\n\u2502   \u2514\u2500\u2500 filtered          &lt;- Seperated raw data, one file is one meassurement\n\u2502   \u2514\u2500\u2500 normalized        &lt;- Normalized filtered data\n\u2502   \u251c\u2500\u2500 processed         &lt;- Torch sensors from normalized data and concatenated csv\n\u2502   \u2514\u2500\u2500 raw               &lt;- Original meassurements\n\u251c\u2500\u2500 deployment            &lt;- Other deployment options as Cloud Function and torchserve\n\u2502   \u2514\u2500\u2500 cloud_functions   &lt;- File that can be run as a Cloud Function on GCP (WIP)\n\u2502   \u2514\u2500\u2500 torchserve/       &lt;- All data needed for local deployment\n\u251c\u2500\u2500 dockerfiles           &lt;- Storage of out dockerfiles\n\u2502   \u2514\u2500\u2500 conda_wheel       &lt;- Setups the machine and open interactive environement\n\u2502   \u251c\u2500\u2500 train_wheel       &lt;- Runs train_model.py that upload the new model to wandb\n\u2502   \u2514\u2500\u2500 serve_model       &lt;- Uses FastAPI, as the only dockerfile also deploys the model\n\u2502   \u2514\u2500\u2500 README            &lt;- Notes and few commands regarding the dockerfiles struggle\n\u251c\u2500\u2500 docs                  &lt;- Documentation folder\n\u2502   \u251c\u2500\u2500 index.md          &lt;- Homepage for your documentation\n\u2502   \u251c\u2500\u2500 mkdocs.yml        &lt;- Configuration file for mkdocs\n\u2502   \u2514\u2500\u2500 source/           &lt;- Source directory for documentation files\n\u251c\u2500\u2500 reports               &lt;- Generated analysis as HTML, PDF, LaTeX, etc.\n\u2502   \u2514\u2500\u2500 figures/          &lt;- Generated graphics and figures to be used in reporting\n\u2502   \u2514\u2500\u2500 README            &lt;- Exam questions and project work progress\n\u251c\u2500\u2500 src                   &lt;- Source code\n\u2502   \u251c\u2500\u2500 data              &lt;- Scripts to download or generate data\n\u2502   \u2502   \u2514\u2500\u2500 filter        &lt;- Seperates the meassurement into csv files\n\u2502   \u2502   \u2514\u2500\u2500 make_dataset  &lt;- Runs filter-&gt;normalize-&gt;process as one script\n\u2502   \u2502   \u2514\u2500\u2500 normalize     &lt;- Normalizes the filtered data\n\u2502   \u2502   \u2514\u2500\u2500 process       &lt;- Changes normalized data into torch files and concatenated csv\n\u2502   \u2502   \u2514\u2500\u2500 README        &lt;- Includes more details about the scripts\n\u2502   \u2502   \u2514\u2500\u2500 utils         &lt;- File with custom functions\n\u2502   \u251c\u2500\u2500 helper            &lt;- Folder with custom functions\n\u2502   \u2502   \u2514\u2500\u2500 convert_reqs  &lt;- Function that mirrors the requirements to environment.yml\n\u2502   \u2502   \u2514\u2500\u2500 gcp_utils     &lt;- Function that returns wandb_api on GCP cloud via secret\n\u2502   \u2502   \u2514\u2500\u2500 logger        &lt;- Creates logs to logs/ folder for easier debugging\n\u2502   \u251c\u2500\u2500 models            &lt;- Model implementations, training script and prediction script\n\u2502   \u2502   \u2514\u2500\u2500 arch_model    &lt;- Old model class definition and function calls\n\u2502   \u2502   \u2514\u2500\u2500 arch_train_m  &lt;- Old model using Forecasting and TemporalFusionTransformer\n\u2502   \u2502   \u2514\u2500\u2500 model         &lt;- New lightweight model class definition and function calls\n\u2502   \u2502   \u2514\u2500\u2500 predict_model &lt;- Predicts the result from unseen data\n\u2502   \u2502   \u2514\u2500\u2500 train_model   &lt;- New lightweight model using Lightning's LTSM\n\u251c\u2500\u2500 tests                 &lt;- Contains all pytest for Github workflow\n\u2502   \u2514\u2500\u2500 test_data         &lt;- Checks if data exist and the data shape\n\u2502   \u251c\u2500\u2500 test_model        &lt;- Check if the trained model is correct\n\u251c\u2500\u2500 .gitignore            &lt;- Data that are now pushed to GitHub\n\u251c\u2500\u2500 .pre-commit-config    &lt;- Formats the code following pep8 and mirror requirements.txt\n\u251c\u2500\u2500 LICENSE               &lt;- Open-source license info\n\u251c\u2500\u2500 Makefile              &lt;- Makefile with convenience commands like `make data` or `make train`\n\u251c\u2500\u2500 README.md             &lt;- The top-level README which you are reading right now\n\u251c\u2500\u2500 data.dvc              &lt;- Links the newest data from GCP Cloud Storage\n\u251c\u2500\u2500 environment.yml       &lt;- Requirements for new conda env, also used inside docker\n\u251c\u2500\u2500 pyproject.toml        &lt;- Project (python) configuration file\n\u2514\u2500\u2500 requirements.txt      &lt;- The pip requirements file for reproducing the environment\n</code></pre>"},{"location":"#acknowledgements","title":"\ud83d\ude4f Acknowledgements","text":"<p>Created using mlops_template, a cookiecutter template for getting started with Machine Learning Operations (MLOps).</p>"},{"location":"commands/","title":"List of Commands","text":""},{"location":"commands/#commands","title":"Commands","text":""},{"location":"commands/#docker","title":"Docker","text":"<ul> <li><code>docker build -f dockerfiles/train_model_vm.dockerfile . -t trainer_vm:latest</code></li> <li><code>docker run --name instance1 -it --entrypoint /bin/bash trainer_vm:latest</code> (interactive mode)</li> <li><code>docker run --name instance1 trainer_vm:latest</code> (just run the docker)</li> <li><code>docker run --name instance1 -v %cd%/models:/models/ trainer_vm:latest</code> (automatically copies the created files inside models to local machine, otherwise they will be only inside the docker)</li> <li><code>docker rm &lt;container_id&gt;</code></li> <li><code>docker run --name test_vm -e WANDB_API_KEY=&lt;WANDB_API_KEY&gt; europe-west1-docker.pkg.dev/wheel-assembly-detection/wheel-assembly-detection-images/train_model_vm:latest</code></li> <li><code>docker pull europe-west1-docker.pkg.dev/wheel-assembly-detection/wheel-assembly-detection-images/train_model_vm:latest</code></li> </ul>"},{"location":"commands/#conda","title":"Conda","text":"<ul> <li><code>conda env create -f environment.yml</code></li> <li><code>conda activate DTU_ML_Ops</code></li> <li><code>conda remove --name DTU_ML_Ops --all</code></li> <li><code>make -f Makefile conda</code></li> </ul>"},{"location":"commands/#gcp","title":"GCP","text":"<ul> <li>create machine: <code>gcloud compute instances create-with-container &lt;name_of_instance&gt; --container-image=&lt;ADDRESS-OF-IMAGE-IN-ARTIFACT-REGISTRY&gt; --project=wheel-assembly-detection --zone=europe-west1-b --machine-type=c2d-standard-4 --maintenance-policy=MIGRATE --provisioning-model=STANDARD --container-restart-policy=never --create-disk=auto-delete=yes,size=20</code></li> <li>locally ssh to the instance: <code>gcloud compute ssh --zone \"europe-west1-b\" \"&lt;name_of_instance&gt;\" --project \"wheel-assembly-detection\"</code></li> <li>authenticate to the correct server: <code>gcloud auth configure-docker europe-west1-docker.pkg.dev</code></li> <li>pull the docker from cloud: <code>docker pull europe-west1-docker.pkg.dev/wheel-assembly-detection/wheel-assembly-detection-images/conda_wheel_assembly_detection:30bfff9d67e13b398188608b94c44662bca1fb06</code></li> </ul>"},{"location":"commands/#gcp-vm","title":"GCP VM","text":"<ul> <li><code>docker ps</code>: shows the docker files running on the machine</li> <li><code>docker logs &lt;CONATINER_ID&gt;</code> wait until its successfully pulled (when the container is finished, I have no clue hot to reach the logs, impossible)</li> <li><code>docker ps</code>: pulled container has new ID</li> <li><code>docker exec -it CONTAINER-ID /bin/bash</code>: starts the docker in interactive window (only the conda_wheel_assemly_detection, the rest only train the model, upload the model and exits, maybe setting the restart policy to \"never\" should fix this issue)</li> <li><code>sudo journalctl -u konlet-startup -n 100</code> (show newest 100 lines only)</li> </ul>"},{"location":"docker/","title":"Docker Notes","text":"<p>In this modified Dockerfile, the conda env create command is used to create a Conda environment based on the environment.yml file. Then, the conda install command is used to install the dependencies specified in the requirements.txt file. The SHELL instruction is used to activate the Conda environment before running the subsequent commands. This approach allows you to reuse the cache from the last build, saving time and resources during the image building process. By following these steps, you can create a Dockerfile that leverages Conda for managing dependencies and efficiently reuses the cache during image builds.</p>"},{"location":"docker/#notes","title":"Notes","text":"<ul> <li>The file name convention is name:tag  (e.g. trainer:latest)</li> <li>We can start as many docker files as we want as long as they have original names docker run --name experiment1 trainer:latest</li> <li>If the file is called Dockerfile, which is the default name, then -f trainer.dockerfile is not needed to type</li> <li>If dvc pull is not working, try to download dvc as a conda package, not using pip</li> <li>Building docker using conda in repeat is 20000x faster (loading from cache does not work using only pip on Windows)</li> <li>Never mix pip and conda, if you want to use only pip (does not cross check with the packages of correct version) dont use conda, if you want to use conda, put all dependencies into environment.yml file and activate the codna environment in the last step.</li> <li>Conda can be very tricky while using in docker, after 7 hours I conclude that you have to be a masochist to use conda in docker. But if it works, great</li> </ul>"},{"location":"docker/#building-process","title":"Building Process","text":"<ul> <li>Normally we would build and store the docker image on GCP</li> <li>However there were issues during the building process</li> <li>Therefore we build it using GitHub workflow and then send it to GCP</li> <li>Now the stores image on GCP can be immediately deployed (both online and locally)</li> </ul>"},{"location":"docker/#commands","title":"Commands","text":"<ul> <li><code>docker build -f train_model.dockerfile . -t trainer:latest</code> (builds trainer image)</li> <li><code>docker build -f conda_setup.dockerfile . -t conda:latest</code> (builds conda image)</li> <li><code>docker run --name instance1 -it --entrypoint /bin/bash train:latest</code> (interactive mode)</li> <li><code>docker run --name instance1 trainer:latest</code> (just run the docker)</li> <li><code>docker run --name instance1 -v %cd%/models:/models/ trainer:latest</code> (automatically copies the created files to local machine, otherwise they will be only inside the docker)</li> <li><code>docker rm &lt;container_id&gt;</code> (removes the specified container)</li> </ul>"},{"location":"improvements/","title":"Improvements","text":""},{"location":"improvements/#improvements","title":"Improvements","text":"<p>On this page we would like to mention possible improvements. </p>"},{"location":"improvements/#make-more-complex-model","title":"Make more complex model","text":"<p>We did not have enoguh data to make a complex model. But adding more hidden layers or multiple LTSM sequences next to each other could potentially improve the results.</p>"},{"location":"improvements/#try-locust","title":"Try locust","text":"<p>Would be great to see how GCP behaves when multiple requests are happening at the same time. For that we could use the Locuts python package. to try it out</p>"},{"location":"improvements/#experiment-with-forecasting","title":"Experiment with Forecasting","text":"<p>In the beginning of the course, we used forecasting package to use for our model. Nevertheless, due to the fact that the package was outdated and also quite complex, we did not use it in the end. Would be nice to experiement a bit more with it and see what does it.</p>"},{"location":"improvements/#upload-the-best-model-to-model-registry","title":"Upload the best model to model registry","text":"<p>Inside the training, we are uploading the new model to model registry. But the point of model registry is to use only the best model we have. Therefore it would be great to implement some logic which would compare the newly trained model and the one we have online to see which one gives better results on a validation test and keep that one as the deployed model used for users predictions.</p>"},{"location":"improvements/#add-caching","title":"Add caching","text":"<p>The caching, even after spending quite a lot of tiem with it still does not work. It does not speed up anything but instead takes quite a lot of space on GitHub. For that reason we decided not to use cache in our project.</p>"},{"location":"improvements/#mirroirng-requirements-wip","title":"Mirroirng requirements (WIP)","text":"<p>We got tried of copying all the requirements to conda environemnt file as well. Therefore we made another pre-ommit that should automatically take alle new requirements from the requirements.txt file and copy them to environemnt.yml for conda.</p>"},{"location":"summary/","title":"Project Summary","text":"<p>We successfuly deployed the model, while followign all the exercises and instructions on the course page. The framework we used is already mentioned in the report as well as in the README file, therfore here we would liek to say few words about what we are proud about and that was not really mandatory for the scope of the project as well as some tasks that were not very relevant for our project.</p>"},{"location":"summary/#irrelevant-features","title":"Irrelevant Features","text":""},{"location":"summary/#data-drifting","title":"Data drifting","text":"<p>The data drigting happens because the new data can not follow the distribution it was trained on or the world simply just change. Our use is to check whether the tyre and wheel was correctly assembled. In this scenario, data drifting is most likely not gonna happen and in case we start assembling new tyre, we must reatrain the entire model.</p>"},{"location":"summary/#prunning","title":"Prunning","text":"<p>Pruinning should speed up the predicitons, removing the synapses that are not really relevant for the final prediction. However, our model is too simple, so the prediction does not take much time at all. For more complex models in the future, it might be relevant, but for no there is no reason for implementing it.</p>"},{"location":"summary/#distributed-data-loading-and-model-training","title":"Distributed data loading and model training","text":"<p>As mentinoed earlier, the model is rather simple, therefore there is not need to distribute the model training. The same is true for the data. We are working with a very small dataset, counting only 100 meassurements. So distributing the data loading does not amke any sense in our case.</p>"},{"location":"summary/#saving-checkpoints","title":"Saving Checkpoints","text":"<p>It's a good practice to also store checkpoints while training the model, to make sure that we can easily continue our training and we do not loose entire progress in case of an error. However for our use case, since the model is very small, this feature is not relevant.</p>"},{"location":"summary/#what-are-we-proud-of","title":"What are we proud of","text":""},{"location":"summary/#mkdocs","title":"Mkdocs","text":"<p>We made quite handy MkDocs for our project. ALthough it can be further improved, it gives somethign extra for the project and might be useful for others as well as for us if we come back to this repository in our future.</p>"},{"location":"summary/#alerts","title":"Alerts","text":"<p>We implemented alerts for the Slack group that we are using to communciate, we receive a notification everytime when new model is deployed, that allows us to e.g. check whether the new model is giving reasonable results or just make sure that the deployment was correct. We are also getting SMS notification everytime when the cloud run is triggered.</p>"},{"location":"summary/#diagram","title":"Diagram","text":"<p>The diagram that shows all the frameworks we used in our project is quite easy to orient in and graphicaly summarizes what tools we used during this project.</p>"},{"location":"summary/#automated-pep8-formating","title":"Automated pep8 formating","text":"<p>As one of the precommits we implemented automatic code formatting. Therefore we can be sure that the code is following the standard even if the commit is not perfect.</p>"},{"location":"summary/#coverage-report","title":"Coverage Report","text":"<p>Our coverage report for each pytest is automatically uplloaded as a comment to each pull request. Therefore it is quite easy to see what coverage we achieve during the pytests.</p>"},{"location":"summary/#hyperparameter-tuning","title":"Hyperparameter tuning","text":"<p>By running the <code>src/models/traun_model.py</code> with argument <code>-sweep</code>, we automcatically do the hyperparameter optimization and store it to wandb for future analysis.</p>"},{"location":"todo/","title":"Slack Canva","text":"<p>Here we would like to store our Slack Canva that we used for distributing the tasks throughout the course.</p>"},{"location":"todo/#week-1","title":"Week 1","text":"<ul> <li>[x] Create a git repository (Lukas M.)</li> <li>[x] Make sure that all team members have write access to the github repository (Lukas M.)</li> <li>[x] Create a dedicated environment for you project to keep track of your packages (Everyone)</li> <li>[x] Create the initial file structure using cookiecutter (Lukas M.)</li> <li>[x] Fill out the make_dataset.py file such that it downloads whatever data you need and (Vra\u0165a)</li> <li>[x] Add a model file and a training script and get that running (Lukas R. +  Liza + Weihang)</li> <li>[x] Use Pytorch-lightning (if applicable) to reduce the amount of boilerplate in your code (Lukas R. + Weihang)</li> <li>[x] Use Weights &amp; Biases to log training progress and other important metrics/artifacts in your code. (Lukas R.)</li> <li>[x] Used Hydra to load the configurations and manage your hyperparameters nope, will be replaced by Lightning CLI </li> <li>[x] Remember to fill out the requirements.txt file with whatever dependencies that you are using (Lukas M.)</li> <li>[x] Setup version control for your data or part of your data (Lukas R.)</li> <li>[x] Construct one or multiple docker files for your code (Lukas M.)</li> <li>[x] When you have something that works somewhat, remember at some point to to some profiling and see if you can optimize your code</li> <li>[x] Build the docker files locally and make sure they work as intended </li> </ul>"},{"location":"todo/#week-2","title":"Week 2","text":"<ul> <li>[x] Write unit tests related to the data part of your code (Lukas M.)</li> <li>[x] Update cache command (Lukas M.)</li> <li>[x] Write unit tests related to model construction and or model training (the tests should be written into test folder and the workflow into .github/workflow folder) (liza)</li> <li>[x] Read the csv from datafolder (Lukas M.)</li> <li>[x] Consider running a hyperparameter optimization sweep. (Liza) </li> <li>[x] Update the dvc bucket with the new files (Lukas R.)</li> <li>[x] path while running <code>python src/data/make_dataset.py</code> is wrong inside conda (works for windows/ubuntu tho, would be nice if someone can double check)</li> <li>[x] columns for <code>src/model/train_model.py</code> are not the same as inside data/processed/dataset_concatenated.csv`</li> <li>[x] Calculate the coverage.</li> <li>[x] Get some continuous integration running on the github repository (Lukas M.)</li> <li>[x] Create a data storage in GCP Bucket for you data and preferable link this with your data version control setup (Lukas R.)</li> <li>[x] Create a trigger workflow for automatically building your docker images (Lukas R.)</li> <li>[x] Get your model training in GCP using either the Engine or Vertex AI</li> <li>[x] Create a FastAPI application that can do inference using your model (Lukas R.)</li> <li>[x] If applicable, consider deploying the model locally using torchserve (liza)</li> <li>[x] Deploy your model in GCP using either Functions or Run as the backend</li> <li>[x] Wandb monitoring  (Lukas R)  https://wandb.ai/02476mlops/automatic-wheel-assembly-detection?workspace=user-lukyrasocha</li> <li>[x] Figure out wandb auth stuff so you can also monitor runs when training via docker (Lukas R)</li> <li>[x] LOGGING!!!! (Lukas R)</li> <li>[x] Save trained model locally (Lukas R.)</li> <li>[x] Save trained model in cloud (so that we can access models that were trained in cloud) (Lukas M.)</li> <li>[x] Hyperparameters (now they are set in the beginning of the file, try calling the training via the client and not the file itself... Try using Lightning CLI? or hydra? \u2192 OmegaConf (Liza)</li> <li>[x] Try automatic hyperparameter tuning using optuna/Lighngtning CLI/Forecasting \u2192 WandB (Liza)</li> </ul>"},{"location":"todo/#week-3","title":"Week 3","text":"<ul> <li>[x] Create documentation using MkDocs (include there your personal notes or the readme from the docs folder) (Lukas M.)</li> <li>[x] Answer the questions that are part of the report</li> <li>[x] Setup monitoring for the system telemetry of your deployed model?</li> <li>[x] Setup monitoring for the performance of your deployed model?</li> </ul>"},{"location":"todo/#brainstorm","title":"BRAINSTORM","text":"<ul> <li>[x] Do we want so save and load checkpoints as well? (might be good practice for large-scale models)</li> <li>[x] Do we want to somehow optimize the parameter tuning (e.g. start already tuning around the best parameters from previous runs maybe?)</li> <li>[x] We are uploading and using last trained model, should we use the best model instead?</li> <li>[x] Should we have just environment.yaml and remove requirements.txt? To reduce overhead</li> </ul>"},{"location":"todo/#check-before-submission","title":"CHECK BEFORE SUBMISSION","text":"<ul> <li>[x] Remember to comply with good coding practices (pep8) while doing the project</li> <li>[x] Do a bit of code typing and remember to document essential parts of your code</li> <li>[x] Check whether docker runs correctly if started from scratch</li> <li>[x] Save slack canva to README</li> <li>[x] Update the fodler structure in README</li> <li>[x] Try making new conda environment and fill all missing/wrong requirements</li> <li>[x] Add branch protection rules to check all pytest before merging</li> <li>[x] Delete useless data from GCP bucket</li> <li>[x] Revisit your initial project description. Did the project turn out as you wanted?</li> <li>[x] Make sure all group members have a understanding about all parts of the project</li> <li>[x] Check if all your code is uploaded to github</li> <li>[x] Change default flag train to sweep? (now its only -wandb_on)</li> <li>[x] Check Coverage Report (now it does not work)(Lukas M.)</li> </ul>"},{"location":"todo/#unnecessary","title":"UNNECESSARY","text":"<ul> <li>[x] If applicable, play around with distributed data loading</li> <li>[x] If applicable, play around with distributed model training</li> <li>[x] Check how robust your model is towards data drifting</li> <li>[x] Play around with quantization, compilation and pruning for you trained models to increase inference speed</li> </ul>"}]}